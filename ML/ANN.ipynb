{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[]\n",
    "features=[]\n",
    "file=open('Training Dataset.arff').read()\n",
    "list=file.split('\\n')\n",
    "data=np.array(list)\n",
    "data_new=[i.split(',') for i in data]\n",
    "data_new=data_new[0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data_new:\n",
    "    labels.append(i[30])\n",
    "data_new = np.array(data_new)\n",
    "features = data_new[:,:-1]\n",
    "# features = features[:, [0, 1, 2, 3, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 18, 21, 23, 24, 25, 26, 27, 28]]\n",
    "features = features[:, [0, 1, 2, 3, 4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 22, 23, 24, 25, 27, 29]]\n",
    "features = np.array(features).astype(np.int)\n",
    "labels = np.array(labels).astype(np.int)\n",
    "features_train = features\n",
    "labels_train = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11054"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "#First Hidden Layer\n",
    "classifier.add(Dense(22, activation='relu', kernel_initializer='RandomUniform', input_dim=22))\n",
    "\n",
    "#Second  Hidden Layer\n",
    "classifier.add(Dense(30, activation='relu', kernel_initializer='random_normal'))\n",
    "\n",
    "#Third  Hidden Layer\n",
    "classifier.add(Dense(18, activation='relu', kernel_initializer='TruncatedNormal'))\n",
    "\n",
    "#Third  Hidden Layer\n",
    "# classifier.add(Dense(12, activation='softplus', kernel_initializer='random_normal'))\n",
    "\n",
    "#Third  Hidden Layer\n",
    "# classifier.add(Dense(12, activation='tanh', kernel_initializer='random_normal'))\n",
    "\n",
    "#Third  Hidden Layer\n",
    "classifier.add(Dense(16, activation='relu', kernel_initializer='random_normal'))\n",
    "\n",
    "#Fourth  Hidden Layer\n",
    "classifier.add(Dense(6, activation='relu', kernel_initializer='random_normal'))\n",
    "\n",
    "#Fifth  Hidden Layer\n",
    "# classifier.add(Dense(4, activation='relu', kernel_initializer='random_normal'))\n",
    "\n",
    "#Sixth  Hidden Layer\n",
    "# classifier.add(Dense(2, activation='hard_sigmoid', kernel_initializer='random_normal'))\n",
    "\n",
    "#Output Layer\n",
    "classifier.add(Dense(1, activation='sigmoid', kernel_initializer='random_normal'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling the neural network\n",
    "classifier.compile(optimizer ='adam',loss='binary_crossentropy', metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "11054/11054 [==============================] - 2s 177us/step - loss: -3.9961 - acc: 0.3256\n",
      "Epoch 2/500\n",
      "11054/11054 [==============================] - 1s 127us/step - loss: -4.9235 - acc: 0.4673\n",
      "Epoch 3/500\n",
      "11054/11054 [==============================] - 1s 124us/step - loss: -5.0703 - acc: 0.4673\n",
      "Epoch 4/500\n",
      "11054/11054 [==============================] - 1s 124us/step - loss: -5.1445 - acc: 0.4661\n",
      "Epoch 5/500\n",
      "11054/11054 [==============================] - 1s 127us/step - loss: -5.1920 - acc: 0.4682\n",
      "Epoch 6/500\n",
      "11054/11054 [==============================] - 1s 125us/step - loss: -5.2297 - acc: 0.4638\n",
      "Epoch 7/500\n",
      "11054/11054 [==============================] - 1s 125us/step - loss: -5.2744 - acc: 0.4626\n",
      "Epoch 8/500\n",
      "11054/11054 [==============================] - 1s 125us/step - loss: -5.3253 - acc: 0.4665\n",
      "Epoch 9/500\n",
      "11054/11054 [==============================] - 1s 125us/step - loss: -5.3404 - acc: 0.4681\n",
      "Epoch 10/500\n",
      "11054/11054 [==============================] - 1s 130us/step - loss: -5.3651 - acc: 0.4672\n",
      "Epoch 11/500\n",
      "11054/11054 [==============================] - 1s 130us/step - loss: -5.3868 - acc: 0.4685\n",
      "Epoch 12/500\n",
      "11054/11054 [==============================] - 1s 131us/step - loss: -5.3836 - acc: 0.4703\n",
      "Epoch 13/500\n",
      "11054/11054 [==============================] - 1s 130us/step - loss: -5.4116 - acc: 0.4644\n",
      "Epoch 14/500\n",
      "11054/11054 [==============================] - 1s 133us/step - loss: -5.4286 - acc: 0.4704\n",
      "Epoch 15/500\n",
      "11054/11054 [==============================] - 1s 129us/step - loss: -5.4489 - acc: 0.4737\n",
      "Epoch 16/500\n",
      "11054/11054 [==============================] - 1s 130us/step - loss: -5.4296 - acc: 0.4694\n",
      "Epoch 17/500\n",
      "11054/11054 [==============================] - 1s 132us/step - loss: -5.4761 - acc: 0.4703\n",
      "Epoch 18/500\n",
      "11054/11054 [==============================] - 1s 131us/step - loss: -5.4377 - acc: 0.4673\n",
      "Epoch 19/500\n",
      "11054/11054 [==============================] - 1s 131us/step - loss: -5.4751 - acc: 0.4726\n",
      "Epoch 20/500\n",
      "11054/11054 [==============================] - 1s 129us/step - loss: -5.5143 - acc: 0.4769\n",
      "Epoch 21/500\n",
      "11054/11054 [==============================] - 1s 130us/step - loss: -5.5032 - acc: 0.4719\n",
      "Epoch 22/500\n",
      "11054/11054 [==============================] - 1s 131us/step - loss: -5.5262 - acc: 0.4761\n",
      "Epoch 23/500\n",
      "11054/11054 [==============================] - 2s 147us/step - loss: -5.5269 - acc: 0.4684\n",
      "Epoch 24/500\n",
      "11054/11054 [==============================] - 1s 134us/step - loss: -5.5498 - acc: 0.4742\n",
      "Epoch 25/500\n",
      "11054/11054 [==============================] - 1s 131us/step - loss: -5.5654 - acc: 0.4748\n",
      "Epoch 26/500\n",
      "11054/11054 [==============================] - 1s 131us/step - loss: -5.5574 - acc: 0.4666\n",
      "Epoch 27/500\n",
      "11054/11054 [==============================] - 1s 131us/step - loss: -5.5679 - acc: 0.4766\n",
      "Epoch 28/500\n",
      "11054/11054 [==============================] - 1s 132us/step - loss: -5.5967 - acc: 0.4776\n",
      "Epoch 29/500\n",
      "11054/11054 [==============================] - 1s 131us/step - loss: -5.5880 - acc: 0.4720\n",
      "Epoch 30/500\n",
      "11054/11054 [==============================] - 1s 132us/step - loss: -5.5921 - acc: 0.4724\n",
      "Epoch 31/500\n",
      "11054/11054 [==============================] - 1s 130us/step - loss: -5.6319 - acc: 0.4767\n",
      "Epoch 32/500\n",
      "11054/11054 [==============================] - 1s 132us/step - loss: -5.6286 - acc: 0.4727\n",
      "Epoch 33/500\n",
      "11054/11054 [==============================] - 2s 137us/step - loss: -5.6715 - acc: 0.4738\n",
      "Epoch 34/500\n",
      "11054/11054 [==============================] - 1s 132us/step - loss: -5.6048 - acc: 0.4712\n",
      "Epoch 35/500\n",
      "11054/11054 [==============================] - 1s 132us/step - loss: -5.6693 - acc: 0.4776\n",
      "Epoch 36/500\n",
      "11054/11054 [==============================] - 1s 133us/step - loss: -5.6473 - acc: 0.4764\n",
      "Epoch 37/500\n",
      "11054/11054 [==============================] - 1s 134us/step - loss: -5.6591 - acc: 0.4764\n",
      "Epoch 38/500\n",
      "11054/11054 [==============================] - 1s 132us/step - loss: -5.6645 - acc: 0.4768\n",
      "Epoch 39/500\n",
      "11054/11054 [==============================] - 1s 132us/step - loss: -5.7090 - acc: 0.4810\n",
      "Epoch 40/500\n",
      "11054/11054 [==============================] - 2s 136us/step - loss: -5.7245 - acc: 0.4813\n",
      "Epoch 41/500\n",
      "11054/11054 [==============================] - 1s 131us/step - loss: -5.7308 - acc: 0.4825\n",
      "Epoch 42/500\n",
      "11054/11054 [==============================] - 1s 135us/step - loss: -5.7425 - acc: 0.4816\n",
      "Epoch 43/500\n",
      "11054/11054 [==============================] - 1s 132us/step - loss: -5.7729 - acc: 0.4863\n",
      "Epoch 44/500\n",
      "11054/11054 [==============================] - 2s 143us/step - loss: -5.7363 - acc: 0.4812\n",
      "Epoch 45/500\n",
      "11054/11054 [==============================] - 2s 142us/step - loss: -5.7610 - acc: 0.4820\n",
      "Epoch 46/500\n",
      "11054/11054 [==============================] - 1s 134us/step - loss: -5.7871 - acc: 0.4841\n",
      "Epoch 47/500\n",
      "11054/11054 [==============================] - 1s 132us/step - loss: -5.8081 - acc: 0.4862\n",
      "Epoch 48/500\n",
      "11054/11054 [==============================] - 1s 133us/step - loss: -5.7687 - acc: 0.4829\n",
      "Epoch 49/500\n",
      "11054/11054 [==============================] - 1s 131us/step - loss: -5.7876 - acc: 0.4871\n",
      "Epoch 50/500\n",
      "11054/11054 [==============================] - 2s 138us/step - loss: -5.7551 - acc: 0.4853\n",
      "Epoch 51/500\n",
      "11054/11054 [==============================] - 1s 133us/step - loss: -5.8634 - acc: 0.4905\n",
      "Epoch 52/500\n",
      "11054/11054 [==============================] - 2s 137us/step - loss: -5.8135 - acc: 0.4900\n",
      "Epoch 53/500\n",
      "11054/11054 [==============================] - 1s 133us/step - loss: -5.8319 - acc: 0.4903\n",
      "Epoch 54/500\n",
      "11054/11054 [==============================] - 1s 134us/step - loss: -5.8650 - acc: 0.4954\n",
      "Epoch 55/500\n",
      "11054/11054 [==============================] - 1s 133us/step - loss: -5.8998 - acc: 0.4917\n",
      "Epoch 56/500\n",
      "11054/11054 [==============================] - 2s 136us/step - loss: -5.8787 - acc: 0.4977\n",
      "Epoch 57/500\n",
      "11054/11054 [==============================] - 1s 134us/step - loss: -5.8759 - acc: 0.4976\n",
      "Epoch 58/500\n",
      "11054/11054 [==============================] - 2s 149us/step - loss: -5.9068 - acc: 0.5004\n",
      "Epoch 59/500\n",
      "11054/11054 [==============================] - 2s 142us/step - loss: -5.9188 - acc: 0.4962\n",
      "Epoch 60/500\n",
      "11054/11054 [==============================] - 2s 150us/step - loss: -5.9049 - acc: 0.5002\n",
      "Epoch 61/500\n",
      "11054/11054 [==============================] - 2s 137us/step - loss: -5.9402 - acc: 0.5026\n",
      "Epoch 62/500\n",
      "11054/11054 [==============================] - 2s 136us/step - loss: -5.8774 - acc: 0.4943\n",
      "Epoch 63/500\n",
      "11054/11054 [==============================] - 2s 145us/step - loss: -5.8746 - acc: 0.5001\n",
      "Epoch 64/500\n",
      "11054/11054 [==============================] - 2s 180us/step - loss: -5.9732 - acc: 0.5016\n",
      "Epoch 65/500\n",
      "11054/11054 [==============================] - 3s 240us/step - loss: -5.9932 - acc: 0.5040\n",
      "Epoch 66/500\n",
      "11054/11054 [==============================] - 2s 223us/step - loss: -5.9341 - acc: 0.5047\n",
      "Epoch 67/500\n",
      "11054/11054 [==============================] - 2s 208us/step - loss: -5.9644 - acc: 0.5011\n",
      "Epoch 68/500\n",
      "11054/11054 [==============================] - 2s 211us/step - loss: -5.9287 - acc: 0.5017\n",
      "Epoch 69/500\n",
      "11054/11054 [==============================] - 2s 210us/step - loss: -5.9411 - acc: 0.4991\n",
      "Epoch 70/500\n",
      "11054/11054 [==============================] - 2s 168us/step - loss: -5.9500 - acc: 0.4965\n",
      "Epoch 71/500\n",
      "11054/11054 [==============================] - 2s 151us/step - loss: -5.9449 - acc: 0.5017\n",
      "Epoch 72/500\n",
      "11054/11054 [==============================] - 2s 188us/step - loss: -5.9209 - acc: 0.5014\n",
      "Epoch 73/500\n",
      "11054/11054 [==============================] - 2s 157us/step - loss: -5.9221 - acc: 0.4981\n",
      "Epoch 74/500\n",
      "11054/11054 [==============================] - 2s 142us/step - loss: -5.9889 - acc: 0.5028\n",
      "Epoch 75/500\n",
      "11054/11054 [==============================] - 2s 137us/step - loss: -6.0168 - acc: 0.5069\n",
      "Epoch 76/500\n",
      "11054/11054 [==============================] - 2s 141us/step - loss: -6.0101 - acc: 0.5081\n",
      "Epoch 77/500\n",
      "11054/11054 [==============================] - 2s 137us/step - loss: -5.9868 - acc: 0.5055\n",
      "Epoch 78/500\n",
      "11054/11054 [==============================] - 2s 137us/step - loss: -5.9595 - acc: 0.5014\n",
      "Epoch 79/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11054/11054 [==============================] - 1s 121us/step - loss: -5.9629 - acc: 0.4967\n",
      "Epoch 80/500\n",
      "11054/11054 [==============================] - 1s 119us/step - loss: -6.0209 - acc: 0.5058\n",
      "Epoch 81/500\n",
      "11054/11054 [==============================] - 1s 119us/step - loss: -6.0139 - acc: 0.5076\n",
      "Epoch 82/500\n",
      "11054/11054 [==============================] - 1s 128us/step - loss: -6.0480 - acc: 0.5075\n",
      "Epoch 83/500\n",
      "11054/11054 [==============================] - 1s 127us/step - loss: -6.0290 - acc: 0.5085\n",
      "Epoch 84/500\n",
      "11054/11054 [==============================] - 1s 120us/step - loss: -5.9068 - acc: 0.5021\n",
      "Epoch 85/500\n",
      "11054/11054 [==============================] - 1s 118us/step - loss: -6.0070 - acc: 0.5058\n",
      "Epoch 86/500\n",
      "11054/11054 [==============================] - 1s 121us/step - loss: -6.0494 - acc: 0.5081\n",
      "Epoch 87/500\n",
      "11054/11054 [==============================] - 1s 121us/step - loss: -5.9667 - acc: 0.5029\n",
      "Epoch 88/500\n",
      "11054/11054 [==============================] - 1s 119us/step - loss: -6.0422 - acc: 0.5061\n",
      "Epoch 89/500\n",
      "11054/11054 [==============================] - 1s 121us/step - loss: -6.0028 - acc: 0.5057\n",
      "Epoch 90/500\n",
      "11054/11054 [==============================] - 1s 123us/step - loss: -5.9499 - acc: 0.4999\n",
      "Epoch 91/500\n",
      "11054/11054 [==============================] - 1s 119us/step - loss: -5.9439 - acc: 0.4996\n",
      "Epoch 92/500\n",
      "11054/11054 [==============================] - 1s 122us/step - loss: -5.9756 - acc: 0.4993\n",
      "Epoch 93/500\n",
      "11054/11054 [==============================] - 1s 120us/step - loss: -5.9548 - acc: 0.5008\n",
      "Epoch 94/500\n",
      "11054/11054 [==============================] - 1s 119us/step - loss: -6.0170 - acc: 0.5044\n",
      "Epoch 95/500\n",
      "11054/11054 [==============================] - 1s 121us/step - loss: -6.0330 - acc: 0.5061\n",
      "Epoch 96/500\n",
      "11054/11054 [==============================] - 1s 120us/step - loss: -6.0367 - acc: 0.5068\n",
      "Epoch 97/500\n",
      "11054/11054 [==============================] - 1s 120us/step - loss: -6.0375 - acc: 0.5062\n",
      "Epoch 98/500\n",
      "11054/11054 [==============================] - 1s 120us/step - loss: -6.0336 - acc: 0.5054\n",
      "Epoch 99/500\n",
      "11054/11054 [==============================] - 1s 121us/step - loss: -6.0568 - acc: 0.5078\n",
      "Epoch 100/500\n",
      "11054/11054 [==============================] - 1s 120us/step - loss: -6.0844 - acc: 0.5091\n",
      "Epoch 101/500\n",
      "11054/11054 [==============================] - 1s 121us/step - loss: -6.0702 - acc: 0.5096\n",
      "Epoch 102/500\n",
      "11054/11054 [==============================] - 1s 124us/step - loss: -5.9675 - acc: 0.4970\n",
      "Epoch 103/500\n",
      "11054/11054 [==============================] - 1s 119us/step - loss: -5.9857 - acc: 0.4973\n",
      "Epoch 104/500\n",
      "11054/11054 [==============================] - 1s 121us/step - loss: -6.0924 - acc: 0.5082\n",
      "Epoch 105/500\n",
      "11054/11054 [==============================] - 1s 122us/step - loss: -6.1006 - acc: 0.5085\n",
      "Epoch 106/500\n",
      "11054/11054 [==============================] - 1s 135us/step - loss: -6.0905 - acc: 0.5070\n",
      "Epoch 107/500\n",
      "11054/11054 [==============================] - 1s 126us/step - loss: -6.0356 - acc: 0.5024\n",
      "Epoch 108/500\n",
      "11054/11054 [==============================] - 1s 136us/step - loss: -6.0648 - acc: 0.5094\n",
      "Epoch 109/500\n",
      "11054/11054 [==============================] - 1s 121us/step - loss: -6.0892 - acc: 0.5077\n",
      "Epoch 110/500\n",
      "11054/11054 [==============================] - 1s 122us/step - loss: -6.0701 - acc: 0.5040\n",
      "Epoch 111/500\n",
      "11054/11054 [==============================] - 1s 124us/step - loss: -6.1202 - acc: 0.5110\n",
      "Epoch 112/500\n",
      "11054/11054 [==============================] - 1s 122us/step - loss: -6.0675 - acc: 0.5041\n",
      "Epoch 113/500\n",
      "11054/11054 [==============================] - 1s 121us/step - loss: -6.1396 - acc: 0.5156\n",
      "Epoch 114/500\n",
      "11054/11054 [==============================] - 2s 154us/step - loss: -6.1185 - acc: 0.5062\n",
      "Epoch 115/500\n",
      "11054/11054 [==============================] - 1s 128us/step - loss: -6.0855 - acc: 0.5097\n",
      "Epoch 116/500\n",
      "11054/11054 [==============================] - 1s 122us/step - loss: -6.0765 - acc: 0.5069\n",
      "Epoch 117/500\n",
      "11054/11054 [==============================] - 1s 123us/step - loss: -6.0745 - acc: 0.5023\n",
      "Epoch 118/500\n",
      "11054/11054 [==============================] - 1s 122us/step - loss: -6.0639 - acc: 0.5041\n",
      "Epoch 119/500\n",
      "11054/11054 [==============================] - 1s 122us/step - loss: -6.1432 - acc: 0.5117\n",
      "Epoch 120/500\n",
      "11054/11054 [==============================] - 1s 125us/step - loss: -6.1204 - acc: 0.5071\n",
      "Epoch 121/500\n",
      "11054/11054 [==============================] - 1s 127us/step - loss: -6.0895 - acc: 0.5096\n",
      "Epoch 122/500\n",
      "11054/11054 [==============================] - 2s 138us/step - loss: -6.0596 - acc: 0.5101\n",
      "Epoch 123/500\n",
      "11054/11054 [==============================] - ETA: 0s - loss: -6.0490 - acc: 0.50 - 2s 142us/step - loss: -6.0484 - acc: 0.5054\n",
      "Epoch 124/500\n",
      "11054/11054 [==============================] - 2s 173us/step - loss: -6.0926 - acc: 0.5097\n",
      "Epoch 125/500\n",
      "11054/11054 [==============================] - 2s 147us/step - loss: -6.1150 - acc: 0.5117\n",
      "Epoch 126/500\n",
      "11054/11054 [==============================] - 2s 138us/step - loss: -6.0931 - acc: 0.5084\n",
      "Epoch 127/500\n",
      "11054/11054 [==============================] - 2s 144us/step - loss: -6.0810 - acc: 0.5082\n",
      "Epoch 128/500\n",
      "11054/11054 [==============================] - 2s 143us/step - loss: -6.1043 - acc: 0.5129\n",
      "Epoch 129/500\n",
      "11054/11054 [==============================] - 1s 131us/step - loss: -6.0939 - acc: 0.5097\n",
      "Epoch 130/500\n",
      "11054/11054 [==============================] - 1s 130us/step - loss: -6.1358 - acc: 0.5133\n",
      "Epoch 131/500\n",
      "11054/11054 [==============================] - 1s 126us/step - loss: -6.1355 - acc: 0.5102\n",
      "Epoch 132/500\n",
      "11054/11054 [==============================] - 1s 124us/step - loss: -6.1472 - acc: 0.5061\n",
      "Epoch 133/500\n",
      "11054/11054 [==============================] - 2s 141us/step - loss: -6.1194 - acc: 0.5078\n",
      "Epoch 134/500\n",
      "11054/11054 [==============================] - 2s 167us/step - loss: -6.1322 - acc: 0.5088\n",
      "Epoch 135/500\n",
      "11054/11054 [==============================] - 2s 180us/step - loss: -6.1404 - acc: 0.5085\n",
      "Epoch 136/500\n",
      "11054/11054 [==============================] - 2s 157us/step - loss: -6.1539 - acc: 0.5101\n",
      "Epoch 137/500\n",
      "11054/11054 [==============================] - 2s 159us/step - loss: -6.1604 - acc: 0.5109\n",
      "Epoch 138/500\n",
      "11054/11054 [==============================] - 2s 153us/step - loss: -6.1606 - acc: 0.5114\n",
      "Epoch 139/500\n",
      "11054/11054 [==============================] - 2s 155us/step - loss: -6.1709 - acc: 0.5132\n",
      "Epoch 140/500\n",
      "11054/11054 [==============================] - 2s 163us/step - loss: -6.1467 - acc: 0.5089\n",
      "Epoch 141/500\n",
      "11054/11054 [==============================] - 2s 154us/step - loss: -6.1240 - acc: 0.5100\n",
      "Epoch 142/500\n",
      "11054/11054 [==============================] - 2s 158us/step - loss: -6.1068 - acc: 0.5052\n",
      "Epoch 143/500\n",
      "11054/11054 [==============================] - 2s 157us/step - loss: -6.1204 - acc: 0.5056\n",
      "Epoch 144/500\n",
      "11054/11054 [==============================] - 2s 155us/step - loss: -6.1320 - acc: 0.5068\n",
      "Epoch 145/500\n",
      "11054/11054 [==============================] - 2s 163us/step - loss: -6.1037 - acc: 0.5072\n",
      "Epoch 146/500\n",
      "11054/11054 [==============================] - 2s 163us/step - loss: -6.1330 - acc: 0.5096\n",
      "Epoch 147/500\n",
      "11054/11054 [==============================] - 2s 170us/step - loss: -6.1411 - acc: 0.5134\n",
      "Epoch 148/500\n",
      "11054/11054 [==============================] - 2s 163us/step - loss: -6.1108 - acc: 0.5116\n",
      "Epoch 149/500\n",
      "11054/11054 [==============================] - 2s 152us/step - loss: -6.1350 - acc: 0.5161\n",
      "Epoch 150/500\n",
      "11054/11054 [==============================] - 2s 140us/step - loss: -6.1126 - acc: 0.5088\n",
      "Epoch 151/500\n",
      "11054/11054 [==============================] - 2s 139us/step - loss: -6.1158 - acc: 0.5157\n",
      "Epoch 152/500\n",
      "11054/11054 [==============================] - ETA: 0s - loss: -6.0942 - acc: 0.50 - 2s 138us/step - loss: -6.1145 - acc: 0.5077\n",
      "Epoch 153/500\n",
      "11054/11054 [==============================] - 2s 161us/step - loss: -6.1413 - acc: 0.5130\n",
      "Epoch 154/500\n",
      "11054/11054 [==============================] - 2s 154us/step - loss: -6.1339 - acc: 0.5069\n",
      "Epoch 155/500\n",
      "11054/11054 [==============================] - 2s 155us/step - loss: -6.1686 - acc: 0.5157\n",
      "Epoch 156/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11054/11054 [==============================] - 2s 162us/step - loss: -6.1636 - acc: 0.5105\n",
      "Epoch 157/500\n",
      "11054/11054 [==============================] - 1s 133us/step - loss: -6.0940 - acc: 0.5047\n",
      "Epoch 158/500\n",
      "11054/11054 [==============================] - 2s 156us/step - loss: -6.1460 - acc: 0.5086\n",
      "Epoch 159/500\n",
      "11054/11054 [==============================] - 1s 135us/step - loss: -6.1816 - acc: 0.5145\n",
      "Epoch 160/500\n",
      "11054/11054 [==============================] - 1s 132us/step - loss: -6.1531 - acc: 0.5153\n",
      "Epoch 161/500\n",
      "11054/11054 [==============================] - 2s 136us/step - loss: -6.1466 - acc: 0.5128\n",
      "Epoch 162/500\n",
      "11054/11054 [==============================] - 1s 122us/step - loss: -6.1393 - acc: 0.5133\n",
      "Epoch 163/500\n",
      "11054/11054 [==============================] - 1s 120us/step - loss: -6.1968 - acc: 0.5147\n",
      "Epoch 164/500\n",
      "11054/11054 [==============================] - 1s 118us/step - loss: -6.1806 - acc: 0.5109\n",
      "Epoch 165/500\n",
      "11054/11054 [==============================] - 1s 120us/step - loss: -6.1259 - acc: 0.5109\n",
      "Epoch 166/500\n",
      "11054/11054 [==============================] - 1s 124us/step - loss: -6.1553 - acc: 0.5113\n",
      "Epoch 167/500\n",
      "11054/11054 [==============================] - 2s 146us/step - loss: -6.2117 - acc: 0.5151\n",
      "Epoch 168/500\n",
      "11054/11054 [==============================] - 2s 139us/step - loss: -6.1418 - acc: 0.5137\n",
      "Epoch 169/500\n",
      "11054/11054 [==============================] - 1s 122us/step - loss: -6.1818 - acc: 0.5168\n",
      "Epoch 170/500\n",
      "11054/11054 [==============================] - 1s 120us/step - loss: -6.2009 - acc: 0.5120\n",
      "Epoch 171/500\n",
      "11054/11054 [==============================] - 1s 123us/step - loss: -6.1904 - acc: 0.5141\n",
      "Epoch 172/500\n",
      "11054/11054 [==============================] - 1s 121us/step - loss: -6.1470 - acc: 0.5092\n",
      "Epoch 173/500\n",
      "11054/11054 [==============================] - 1s 120us/step - loss: -6.1577 - acc: 0.5113\n",
      "Epoch 174/500\n",
      "11054/11054 [==============================] - 1s 123us/step - loss: -6.2147 - acc: 0.5121\n",
      "Epoch 175/500\n",
      "11054/11054 [==============================] - 1s 121us/step - loss: -6.1712 - acc: 0.5116\n",
      "Epoch 176/500\n",
      "11054/11054 [==============================] - 1s 121us/step - loss: -6.1557 - acc: 0.5126\n",
      "Epoch 177/500\n",
      "11054/11054 [==============================] - 1s 122us/step - loss: -6.1763 - acc: 0.5110\n",
      "Epoch 178/500\n",
      "11054/11054 [==============================] - 1s 122us/step - loss: -6.1610 - acc: 0.5140\n",
      "Epoch 179/500\n",
      "11054/11054 [==============================] - 1s 121us/step - loss: -6.2271 - acc: 0.5126\n",
      "Epoch 180/500\n",
      "11054/11054 [==============================] - 1s 123us/step - loss: -6.2039 - acc: 0.5111\n",
      "Epoch 181/500\n",
      "11054/11054 [==============================] - 1s 124us/step - loss: -6.1747 - acc: 0.5131\n",
      "Epoch 182/500\n",
      "11054/11054 [==============================] - 1s 126us/step - loss: -6.2221 - acc: 0.5131\n",
      "Epoch 183/500\n",
      "11054/11054 [==============================] - 1s 133us/step - loss: -6.1751 - acc: 0.5099\n",
      "Epoch 184/500\n",
      "11054/11054 [==============================] - 1s 121us/step - loss: -6.2015 - acc: 0.5180\n",
      "Epoch 185/500\n",
      "11054/11054 [==============================] - 1s 122us/step - loss: -6.1521 - acc: 0.5074\n",
      "Epoch 186/500\n",
      "11054/11054 [==============================] - 1s 122us/step - loss: -6.1415 - acc: 0.5042\n",
      "Epoch 187/500\n",
      "11054/11054 [==============================] - 1s 122us/step - loss: -6.1866 - acc: 0.5116\n",
      "Epoch 188/500\n",
      "11054/11054 [==============================] - 1s 122us/step - loss: -6.1778 - acc: 0.5152\n",
      "Epoch 189/500\n",
      "11054/11054 [==============================] - 1s 122us/step - loss: -6.1983 - acc: 0.5109\n",
      "Epoch 190/500\n",
      "11054/11054 [==============================] - 1s 126us/step - loss: -6.1501 - acc: 0.5133\n",
      "Epoch 191/500\n",
      "11054/11054 [==============================] - 1s 123us/step - loss: -6.1557 - acc: 0.5081\n",
      "Epoch 192/500\n",
      "11054/11054 [==============================] - 1s 122us/step - loss: -6.1794 - acc: 0.5092\n",
      "Epoch 193/500\n",
      "11054/11054 [==============================] - 1s 123us/step - loss: -6.2139 - acc: 0.5076\n",
      "Epoch 194/500\n",
      "11054/11054 [==============================] - 1s 123us/step - loss: -6.1782 - acc: 0.5062\n",
      "Epoch 195/500\n",
      "11054/11054 [==============================] - 1s 123us/step - loss: -6.2263 - acc: 0.5119\n",
      "Epoch 196/500\n",
      "11054/11054 [==============================] - 1s 123us/step - loss: -6.1626 - acc: 0.5092\n",
      "Epoch 197/500\n",
      "11054/11054 [==============================] - 1s 123us/step - loss: -6.2167 - acc: 0.5124\n",
      "Epoch 198/500\n",
      "11054/11054 [==============================] - 1s 122us/step - loss: -6.2315 - acc: 0.5157\n",
      "Epoch 199/500\n",
      "11054/11054 [==============================] - 1s 123us/step - loss: -6.2584 - acc: 0.5149\n",
      "Epoch 200/500\n",
      "11054/11054 [==============================] - 1s 125us/step - loss: -6.2298 - acc: 0.5119\n",
      "Epoch 201/500\n",
      "11054/11054 [==============================] - 1s 122us/step - loss: -6.2357 - acc: 0.5116\n",
      "Epoch 202/500\n",
      "11054/11054 [==============================] - 1s 125us/step - loss: -6.1692 - acc: 0.5117\n",
      "Epoch 203/500\n",
      "11054/11054 [==============================] - 1s 124us/step - loss: -6.2653 - acc: 0.5164\n",
      "Epoch 204/500\n",
      "11054/11054 [==============================] - 1s 123us/step - loss: -6.1285 - acc: 0.5095\n",
      "Epoch 205/500\n",
      "11054/11054 [==============================] - 1s 124us/step - loss: -6.2283 - acc: 0.5135\n",
      "Epoch 206/500\n",
      "11054/11054 [==============================] - 1s 124us/step - loss: -6.1506 - acc: 0.5081\n",
      "Epoch 207/500\n",
      "11054/11054 [==============================] - 1s 124us/step - loss: -6.2354 - acc: 0.5123\n",
      "Epoch 208/500\n",
      "11054/11054 [==============================] - 1s 124us/step - loss: -6.1858 - acc: 0.5161\n",
      "Epoch 209/500\n",
      "11054/11054 [==============================] - 1s 124us/step - loss: -6.1685 - acc: 0.5116\n",
      "Epoch 210/500\n",
      "11054/11054 [==============================] - 1s 126us/step - loss: -6.2529 - acc: 0.5164\n",
      "Epoch 211/500\n",
      "11054/11054 [==============================] - 1s 122us/step - loss: -6.2560 - acc: 0.5147\n",
      "Epoch 212/500\n",
      "11054/11054 [==============================] - 1s 124us/step - loss: -6.2413 - acc: 0.5147\n",
      "Epoch 213/500\n",
      "11054/11054 [==============================] - 1s 124us/step - loss: -6.1819 - acc: 0.5119\n",
      "Epoch 214/500\n",
      "11054/11054 [==============================] - 1s 124us/step - loss: -6.1874 - acc: 0.5156\n",
      "Epoch 215/500\n",
      "11054/11054 [==============================] - 1s 124us/step - loss: -6.2136 - acc: 0.5191\n",
      "Epoch 216/500\n",
      "11054/11054 [==============================] - 1s 124us/step - loss: -6.2157 - acc: 0.5160\n",
      "Epoch 217/500\n",
      "11054/11054 [==============================] - 1s 124us/step - loss: -6.1848 - acc: 0.5177\n",
      "Epoch 218/500\n",
      "11054/11054 [==============================] - 2s 137us/step - loss: -6.1920 - acc: 0.5144\n",
      "Epoch 219/500\n",
      "11054/11054 [==============================] - 1s 128us/step - loss: -6.1859 - acc: 0.5139\n",
      "Epoch 220/500\n",
      "11054/11054 [==============================] - 1s 125us/step - loss: -6.1933 - acc: 0.5149\n",
      "Epoch 221/500\n",
      "11054/11054 [==============================] - 2s 137us/step - loss: -6.2491 - acc: 0.5174\n",
      "Epoch 222/500\n",
      "11054/11054 [==============================] - 1s 129us/step - loss: -6.2511 - acc: 0.5192\n",
      "Epoch 223/500\n",
      "11054/11054 [==============================] - 1s 127us/step - loss: -6.2491 - acc: 0.5196\n",
      "Epoch 224/500\n",
      "11054/11054 [==============================] - 1s 125us/step - loss: -6.2635 - acc: 0.5185\n",
      "Epoch 225/500\n",
      "11054/11054 [==============================] - 1s 129us/step - loss: -6.2891 - acc: 0.5211\n",
      "Epoch 226/500\n",
      "11054/11054 [==============================] - 1s 127us/step - loss: -6.2046 - acc: 0.5127\n",
      "Epoch 227/500\n",
      "11054/11054 [==============================] - 1s 126us/step - loss: -6.1556 - acc: 0.5120\n",
      "Epoch 228/500\n",
      "11054/11054 [==============================] - 1s 127us/step - loss: -6.2498 - acc: 0.5166\n",
      "Epoch 229/500\n",
      "11054/11054 [==============================] - 1s 128us/step - loss: -6.1834 - acc: 0.5147\n",
      "Epoch 230/500\n",
      "11054/11054 [==============================] - 1s 128us/step - loss: -6.2041 - acc: 0.5155\n",
      "Epoch 231/500\n",
      "11054/11054 [==============================] - 1s 127us/step - loss: -6.2237 - acc: 0.5162\n",
      "Epoch 232/500\n",
      "11054/11054 [==============================] - 1s 127us/step - loss: -6.2162 - acc: 0.5162\n",
      "Epoch 233/500\n",
      "11054/11054 [==============================] - 1s 126us/step - loss: -6.2029 - acc: 0.5153\n",
      "Epoch 234/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11054/11054 [==============================] - 1s 123us/step - loss: -6.2487 - acc: 0.5157\n",
      "Epoch 235/500\n",
      "11054/11054 [==============================] - 1s 121us/step - loss: -6.2754 - acc: 0.5194\n",
      "Epoch 236/500\n",
      "11054/11054 [==============================] - 1s 121us/step - loss: -6.2491 - acc: 0.5182\n",
      "Epoch 237/500\n",
      "11054/11054 [==============================] - 1s 119us/step - loss: -6.1825 - acc: 0.5139\n",
      "Epoch 238/500\n",
      "11054/11054 [==============================] - 1s 119us/step - loss: -6.2343 - acc: 0.5191\n",
      "Epoch 239/500\n",
      "11054/11054 [==============================] - 1s 122us/step - loss: -6.2767 - acc: 0.5176\n",
      "Epoch 240/500\n",
      "11054/11054 [==============================] - 1s 119us/step - loss: -6.2303 - acc: 0.5164\n",
      "Epoch 241/500\n",
      "11054/11054 [==============================] - 1s 120us/step - loss: -6.2372 - acc: 0.5186\n",
      "Epoch 242/500\n",
      "11054/11054 [==============================] - 1s 121us/step - loss: -6.2047 - acc: 0.5175\n",
      "Epoch 243/500\n",
      "11054/11054 [==============================] - 1s 121us/step - loss: -6.2492 - acc: 0.5180\n",
      "Epoch 244/500\n",
      "11054/11054 [==============================] - 1s 120us/step - loss: -6.2257 - acc: 0.5130\n",
      "Epoch 245/500\n",
      "11054/11054 [==============================] - 1s 119us/step - loss: -6.2426 - acc: 0.5145\n",
      "Epoch 246/500\n",
      "11054/11054 [==============================] - 1s 135us/step - loss: -6.1544 - acc: 0.5096\n",
      "Epoch 247/500\n",
      "11054/11054 [==============================] - 1s 125us/step - loss: -6.1943 - acc: 0.5175\n",
      "Epoch 248/500\n",
      "11054/11054 [==============================] - 1s 132us/step - loss: -6.1755 - acc: 0.5152\n",
      "Epoch 249/500\n",
      "11054/11054 [==============================] - 1s 123us/step - loss: -6.2203 - acc: 0.5152\n",
      "Epoch 250/500\n",
      "11054/11054 [==============================] - 1s 121us/step - loss: -6.2372 - acc: 0.5159\n",
      "Epoch 251/500\n",
      "11054/11054 [==============================] - 1s 120us/step - loss: -6.2168 - acc: 0.5141\n",
      "Epoch 252/500\n",
      "11054/11054 [==============================] - 1s 121us/step - loss: -6.2546 - acc: 0.5115\n",
      "Epoch 253/500\n",
      "11054/11054 [==============================] - 1s 122us/step - loss: -6.0477 - acc: 0.5041\n",
      "Epoch 254/500\n",
      "11054/11054 [==============================] - 1s 121us/step - loss: -6.1215 - acc: 0.5113\n",
      "Epoch 255/500\n",
      "11054/11054 [==============================] - 1s 120us/step - loss: -6.2574 - acc: 0.5188\n",
      "Epoch 256/500\n",
      "11054/11054 [==============================] - 1s 121us/step - loss: -6.2682 - acc: 0.5149\n",
      "Epoch 257/500\n",
      "11054/11054 [==============================] - 1s 121us/step - loss: -6.2434 - acc: 0.5140\n",
      "Epoch 258/500\n",
      "11054/11054 [==============================] - 1s 123us/step - loss: -6.2539 - acc: 0.5161\n",
      "Epoch 259/500\n",
      "11054/11054 [==============================] - 1s 120us/step - loss: -6.2849 - acc: 0.5184\n",
      "Epoch 260/500\n",
      "11054/11054 [==============================] - 1s 122us/step - loss: -6.2492 - acc: 0.5136\n",
      "Epoch 261/500\n",
      "11054/11054 [==============================] - 1s 121us/step - loss: -6.1328 - acc: 0.5055\n",
      "Epoch 262/500\n",
      "11054/11054 [==============================] - 1s 121us/step - loss: -6.2376 - acc: 0.5093\n",
      "Epoch 263/500\n",
      "11054/11054 [==============================] - 1s 121us/step - loss: -6.2637 - acc: 0.5189\n",
      "Epoch 264/500\n",
      "11054/11054 [==============================] - 1s 123us/step - loss: -6.2673 - acc: 0.5203\n",
      "Epoch 265/500\n",
      "11054/11054 [==============================] - 1s 122us/step - loss: -6.2766 - acc: 0.5196\n",
      "Epoch 266/500\n",
      "11054/11054 [==============================] - 1s 122us/step - loss: -6.2213 - acc: 0.5166\n",
      "Epoch 267/500\n",
      "11054/11054 [==============================] - 1s 120us/step - loss: -6.2042 - acc: 0.5137\n",
      "Epoch 268/500\n",
      "11054/11054 [==============================] - 1s 122us/step - loss: -6.3313 - acc: 0.5217\n",
      "Epoch 269/500\n",
      "11054/11054 [==============================] - 1s 122us/step - loss: -6.1984 - acc: 0.5138\n",
      "Epoch 270/500\n",
      "11054/11054 [==============================] - 1s 122us/step - loss: -6.3024 - acc: 0.5186\n",
      "Epoch 271/500\n",
      "11054/11054 [==============================] - 1s 122us/step - loss: -6.2190 - acc: 0.5160\n",
      "Epoch 272/500\n",
      "11054/11054 [==============================] - 1s 123us/step - loss: -6.2557 - acc: 0.5176\n",
      "Epoch 273/500\n",
      "11054/11054 [==============================] - 1s 123us/step - loss: -6.2806 - acc: 0.5213\n",
      "Epoch 274/500\n",
      "11054/11054 [==============================] - 1s 123us/step - loss: -6.2864 - acc: 0.5176\n",
      "Epoch 275/500\n",
      "11054/11054 [==============================] - 1s 123us/step - loss: -6.2850 - acc: 0.5213\n",
      "Epoch 276/500\n",
      "11054/11054 [==============================] - 1s 124us/step - loss: -6.2767 - acc: 0.5183\n",
      "Epoch 277/500\n",
      "11054/11054 [==============================] - 1s 121us/step - loss: -6.2306 - acc: 0.5144\n",
      "Epoch 278/500\n",
      "11054/11054 [==============================] - 1s 124us/step - loss: -6.1979 - acc: 0.5166\n",
      "Epoch 279/500\n",
      "11054/11054 [==============================] - 1s 123us/step - loss: -6.2324 - acc: 0.5177\n",
      "Epoch 280/500\n",
      "11054/11054 [==============================] - 1s 123us/step - loss: -6.2345 - acc: 0.5158\n",
      "Epoch 281/500\n",
      "11054/11054 [==============================] - 1s 123us/step - loss: -6.2164 - acc: 0.5131\n",
      "Epoch 282/500\n",
      "11054/11054 [==============================] - 1s 124us/step - loss: -6.1347 - acc: 0.5090\n",
      "Epoch 283/500\n",
      "11054/11054 [==============================] - 1s 125us/step - loss: -6.2644 - acc: 0.5196\n",
      "Epoch 284/500\n",
      "11054/11054 [==============================] - 1s 122us/step - loss: -6.2070 - acc: 0.5140\n",
      "Epoch 285/500\n",
      "11054/11054 [==============================] - 1s 123us/step - loss: -6.2278 - acc: 0.5143\n",
      "Epoch 286/500\n",
      "11054/11054 [==============================] - 1s 123us/step - loss: -6.2407 - acc: 0.5144\n",
      "Epoch 287/500\n",
      "11054/11054 [==============================] - 1s 122us/step - loss: -6.2501 - acc: 0.5139\n",
      "Epoch 288/500\n",
      "11054/11054 [==============================] - 1s 125us/step - loss: -6.2921 - acc: 0.5163\n",
      "Epoch 289/500\n",
      "11054/11054 [==============================] - 1s 124us/step - loss: -6.2433 - acc: 0.5189\n",
      "Epoch 290/500\n",
      "11054/11054 [==============================] - 1s 123us/step - loss: -6.2373 - acc: 0.5091\n",
      "Epoch 291/500\n",
      "11054/11054 [==============================] - 1s 128us/step - loss: -6.2842 - acc: 0.5150\n",
      "Epoch 292/500\n",
      "11054/11054 [==============================] - 1s 124us/step - loss: -6.2431 - acc: 0.5157\n",
      "Epoch 293/500\n",
      "11054/11054 [==============================] - 1s 121us/step - loss: -6.2866 - acc: 0.5229\n",
      "Epoch 294/500\n",
      "11054/11054 [==============================] - 1s 124us/step - loss: -6.2889 - acc: 0.5210\n",
      "Epoch 295/500\n",
      "11054/11054 [==============================] - 1s 124us/step - loss: -6.3014 - acc: 0.5220\n",
      "Epoch 296/500\n",
      "11054/11054 [==============================] - 1s 124us/step - loss: -6.3062 - acc: 0.5209\n",
      "Epoch 297/500\n",
      "11054/11054 [==============================] - 1s 124us/step - loss: -6.2778 - acc: 0.5206\n",
      "Epoch 298/500\n",
      "11054/11054 [==============================] - 1s 126us/step - loss: -6.3037 - acc: 0.5214\n",
      "Epoch 299/500\n",
      "11054/11054 [==============================] - 1s 128us/step - loss: -6.3137 - acc: 0.5232\n",
      "Epoch 300/500\n",
      "11054/11054 [==============================] - 1s 125us/step - loss: -6.3016 - acc: 0.5191\n",
      "Epoch 301/500\n",
      "11054/11054 [==============================] - 1s 127us/step - loss: -6.2358 - acc: 0.5144\n",
      "Epoch 302/500\n",
      "11054/11054 [==============================] - 1s 127us/step - loss: -6.1928 - acc: 0.5077\n",
      "Epoch 303/500\n",
      "11054/11054 [==============================] - 1s 125us/step - loss: -6.2705 - acc: 0.5148\n",
      "Epoch 304/500\n",
      "11054/11054 [==============================] - 1s 125us/step - loss: -6.2627 - acc: 0.5176\n",
      "Epoch 305/500\n",
      "11054/11054 [==============================] - 1s 131us/step - loss: -6.3189 - acc: 0.5236\n",
      "Epoch 306/500\n",
      "11054/11054 [==============================] - 1s 135us/step - loss: -6.2432 - acc: 0.5195\n",
      "Epoch 307/500\n",
      "11054/11054 [==============================] - 1s 127us/step - loss: -6.1717 - acc: 0.5019\n",
      "Epoch 308/500\n",
      "11054/11054 [==============================] - 1s 134us/step - loss: -6.2406 - acc: 0.5140\n",
      "Epoch 309/500\n",
      "11054/11054 [==============================] - 2s 138us/step - loss: -6.1964 - acc: 0.5099\n",
      "Epoch 310/500\n",
      "11054/11054 [==============================] - 1s 127us/step - loss: -6.2243 - acc: 0.5027\n",
      "Epoch 311/500\n",
      "11054/11054 [==============================] - 1s 125us/step - loss: -6.2352 - acc: 0.5155\n",
      "Epoch 312/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11054/11054 [==============================] - 1s 123us/step - loss: -6.2620 - acc: 0.5172\n",
      "Epoch 313/500\n",
      "11054/11054 [==============================] - 1s 119us/step - loss: -6.2765 - acc: 0.5172\n",
      "Epoch 314/500\n",
      "11054/11054 [==============================] - 1s 119us/step - loss: -6.2967 - acc: 0.5231\n",
      "Epoch 315/500\n",
      "11054/11054 [==============================] - 1s 119us/step - loss: -6.2714 - acc: 0.5189\n",
      "Epoch 316/500\n",
      "11054/11054 [==============================] - 1s 120us/step - loss: -6.3228 - acc: 0.5212\n",
      "Epoch 317/500\n",
      "11054/11054 [==============================] - 1s 122us/step - loss: -6.2217 - acc: 0.5138\n",
      "Epoch 318/500\n",
      "11054/11054 [==============================] - 1s 119us/step - loss: -6.2828 - acc: 0.5190\n",
      "Epoch 319/500\n",
      "11054/11054 [==============================] - 1s 119us/step - loss: -6.3243 - acc: 0.5213\n",
      "Epoch 320/500\n",
      "11054/11054 [==============================] - 1s 121us/step - loss: -6.2612 - acc: 0.5176\n",
      "Epoch 321/500\n",
      "11054/11054 [==============================] - 2s 139us/step - loss: -6.2359 - acc: 0.5154\n",
      "Epoch 322/500\n",
      "11054/11054 [==============================] - 2s 151us/step - loss: -6.2511 - acc: 0.5162\n",
      "Epoch 323/500\n",
      "11054/11054 [==============================] - 2s 172us/step - loss: -6.3370 - acc: 0.5225\n",
      "Epoch 324/500\n",
      "11054/11054 [==============================] - 2s 160us/step - loss: -6.2254 - acc: 0.5157\n",
      "Epoch 325/500\n",
      "11054/11054 [==============================] - 2s 164us/step - loss: -6.2532 - acc: 0.5160\n",
      "Epoch 326/500\n",
      "11054/11054 [==============================] - 1s 134us/step - loss: -6.2661 - acc: 0.5213\n",
      "Epoch 327/500\n",
      "11054/11054 [==============================] - 1s 134us/step - loss: -6.3315 - acc: 0.5174\n",
      "Epoch 328/500\n",
      "11054/11054 [==============================] - 1s 129us/step - loss: -6.2859 - acc: 0.5153\n",
      "Epoch 329/500\n",
      "11054/11054 [==============================] - 1s 131us/step - loss: -6.2673 - acc: 0.5103\n",
      "Epoch 330/500\n",
      "11054/11054 [==============================] - 1s 133us/step - loss: -6.2752 - acc: 0.5157\n",
      "Epoch 331/500\n",
      "11054/11054 [==============================] - 1s 130us/step - loss: -6.2717 - acc: 0.5130\n",
      "Epoch 332/500\n",
      "11054/11054 [==============================] - 2s 138us/step - loss: -6.3088 - acc: 0.5185\n",
      "Epoch 333/500\n",
      "11054/11054 [==============================] - 2s 140us/step - loss: -6.2904 - acc: 0.5227\n",
      "Epoch 334/500\n",
      "11054/11054 [==============================] - 2s 138us/step - loss: -6.3061 - acc: 0.5170\n",
      "Epoch 335/500\n",
      "11054/11054 [==============================] - 2s 137us/step - loss: -6.3272 - acc: 0.5214\n",
      "Epoch 336/500\n",
      "11054/11054 [==============================] - 2s 137us/step - loss: -6.3437 - acc: 0.5196\n",
      "Epoch 337/500\n",
      "11054/11054 [==============================] - 2s 137us/step - loss: -6.3231 - acc: 0.5193\n",
      "Epoch 338/500\n",
      "11054/11054 [==============================] - 2s 138us/step - loss: -6.3256 - acc: 0.5210\n",
      "Epoch 339/500\n",
      "11054/11054 [==============================] - 2s 136us/step - loss: -6.3092 - acc: 0.5172\n",
      "Epoch 340/500\n",
      "11054/11054 [==============================] - 2s 139us/step - loss: -6.2599 - acc: 0.5192\n",
      "Epoch 341/500\n",
      "11054/11054 [==============================] - 1s 134us/step - loss: -6.2753 - acc: 0.5169\n",
      "Epoch 342/500\n",
      "11054/11054 [==============================] - 1s 131us/step - loss: -6.2922 - acc: 0.5158\n",
      "Epoch 343/500\n",
      "11054/11054 [==============================] - 1s 132us/step - loss: -6.3328 - acc: 0.5219\n",
      "Epoch 344/500\n",
      "11054/11054 [==============================] - 1s 134us/step - loss: -6.3330 - acc: 0.5202\n",
      "Epoch 345/500\n",
      "11054/11054 [==============================] - 1s 130us/step - loss: -6.3533 - acc: 0.5242\n",
      "Epoch 346/500\n",
      "11054/11054 [==============================] - 1s 131us/step - loss: -6.3471 - acc: 0.5214\n",
      "Epoch 347/500\n",
      "11054/11054 [==============================] - 1s 133us/step - loss: -6.2961 - acc: 0.5168\n",
      "Epoch 348/500\n",
      "11054/11054 [==============================] - 1s 131us/step - loss: -6.2968 - acc: 0.5208\n",
      "Epoch 349/500\n",
      "11054/11054 [==============================] - 1s 133us/step - loss: -6.3444 - acc: 0.5235\n",
      "Epoch 350/500\n",
      "11054/11054 [==============================] - 1s 132us/step - loss: -6.3578 - acc: 0.5190\n",
      "Epoch 351/500\n",
      "11054/11054 [==============================] - 1s 131us/step - loss: -6.3547 - acc: 0.5222\n",
      "Epoch 352/500\n",
      "11054/11054 [==============================] - 1s 132us/step - loss: -6.3362 - acc: 0.5195\n",
      "Epoch 353/500\n",
      "11054/11054 [==============================] - 1s 134us/step - loss: -6.3195 - acc: 0.5168\n",
      "Epoch 354/500\n",
      "11054/11054 [==============================] - 1s 132us/step - loss: -6.3016 - acc: 0.5201\n",
      "Epoch 355/500\n",
      "11054/11054 [==============================] - 1s 132us/step - loss: -6.3356 - acc: 0.5187\n",
      "Epoch 356/500\n",
      "11054/11054 [==============================] - 1s 131us/step - loss: -6.3153 - acc: 0.5204\n",
      "Epoch 357/500\n",
      "11054/11054 [==============================] - 1s 133us/step - loss: -6.3143 - acc: 0.5155\n",
      "Epoch 358/500\n",
      "11054/11054 [==============================] - 1s 133us/step - loss: -6.3364 - acc: 0.5174\n",
      "Epoch 359/500\n",
      "11054/11054 [==============================] - 1s 133us/step - loss: -6.3473 - acc: 0.5181\n",
      "Epoch 360/500\n",
      "11054/11054 [==============================] - 2s 136us/step - loss: -6.3479 - acc: 0.5238\n",
      "Epoch 361/500\n",
      "11054/11054 [==============================] - 1s 133us/step - loss: -6.3317 - acc: 0.5188\n",
      "Epoch 362/500\n",
      "11054/11054 [==============================] - 2s 139us/step - loss: -6.3302 - acc: 0.5202\n",
      "Epoch 363/500\n",
      "11054/11054 [==============================] - 2s 149us/step - loss: -6.3307 - acc: 0.5202\n",
      "Epoch 364/500\n",
      "11054/11054 [==============================] - 2s 149us/step - loss: -6.3480 - acc: 0.5194\n",
      "Epoch 365/500\n",
      "11054/11054 [==============================] - 2s 153us/step - loss: -6.3429 - acc: 0.5224\n",
      "Epoch 366/500\n",
      "11054/11054 [==============================] - 2s 150us/step - loss: -6.3274 - acc: 0.5162\n",
      "Epoch 367/500\n",
      "11054/11054 [==============================] - 2s 149us/step - loss: -6.3401 - acc: 0.5232\n",
      "Epoch 368/500\n",
      "11054/11054 [==============================] - 2s 150us/step - loss: -6.2972 - acc: 0.5162\n",
      "Epoch 369/500\n",
      "11054/11054 [==============================] - 2s 140us/step - loss: -6.3366 - acc: 0.5187\n",
      "Epoch 370/500\n",
      "11054/11054 [==============================] - 2s 141us/step - loss: -6.3634 - acc: 0.5229\n",
      "Epoch 371/500\n",
      "11054/11054 [==============================] - 2s 137us/step - loss: -6.3226 - acc: 0.5207\n",
      "Epoch 372/500\n",
      "11054/11054 [==============================] - 1s 135us/step - loss: -6.3587 - acc: 0.5221\n",
      "Epoch 373/500\n",
      "11054/11054 [==============================] - 1s 134us/step - loss: -6.3631 - acc: 0.5221\n",
      "Epoch 374/500\n",
      "11054/11054 [==============================] - 1s 134us/step - loss: -6.3748 - acc: 0.5233\n",
      "Epoch 375/500\n",
      "11054/11054 [==============================] - 1s 134us/step - loss: -6.3449 - acc: 0.5205\n",
      "Epoch 376/500\n",
      "11054/11054 [==============================] - 1s 136us/step - loss: -6.3542 - acc: 0.5212\n",
      "Epoch 377/500\n",
      "11054/11054 [==============================] - 2s 136us/step - loss: -6.2734 - acc: 0.5177\n",
      "Epoch 378/500\n",
      "11054/11054 [==============================] - 1s 135us/step - loss: -6.3388 - acc: 0.5190\n",
      "Epoch 379/500\n",
      "11054/11054 [==============================] - 2s 136us/step - loss: -6.3537 - acc: 0.5218\n",
      "Epoch 380/500\n",
      "11054/11054 [==============================] - 1s 135us/step - loss: -6.3124 - acc: 0.5188\n",
      "Epoch 381/500\n",
      "11054/11054 [==============================] - 1s 135us/step - loss: -6.3543 - acc: 0.5228\n",
      "Epoch 382/500\n",
      "11054/11054 [==============================] - 1s 134us/step - loss: -6.3223 - acc: 0.5222\n",
      "Epoch 383/500\n",
      "11054/11054 [==============================] - 1s 135us/step - loss: -6.3654 - acc: 0.5192\n",
      "Epoch 384/500\n",
      "11054/11054 [==============================] - 2s 137us/step - loss: -6.3473 - acc: 0.5194\n",
      "Epoch 385/500\n",
      "11054/11054 [==============================] - 2s 139us/step - loss: -6.3431 - acc: 0.5230\n",
      "Epoch 386/500\n",
      "11054/11054 [==============================] - 2s 146us/step - loss: -6.3428 - acc: 0.5196\n",
      "Epoch 387/500\n",
      "11054/11054 [==============================] - 2s 138us/step - loss: -6.3666 - acc: 0.5197\n",
      "Epoch 388/500\n",
      "11054/11054 [==============================] - 2s 150us/step - loss: -6.3492 - acc: 0.5217\n",
      "Epoch 389/500\n",
      "11054/11054 [==============================] - 2s 141us/step - loss: -6.3399 - acc: 0.5134\n",
      "Epoch 390/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11054/11054 [==============================] - 1s 120us/step - loss: -6.3243 - acc: 0.5202\n",
      "Epoch 391/500\n",
      "11054/11054 [==============================] - 1s 118us/step - loss: -6.3600 - acc: 0.5194\n",
      "Epoch 392/500\n",
      "11054/11054 [==============================] - 1s 122us/step - loss: -6.3532 - acc: 0.5223\n",
      "Epoch 393/500\n",
      "11054/11054 [==============================] - 1s 119us/step - loss: -6.3441 - acc: 0.5212\n",
      "Epoch 394/500\n",
      "11054/11054 [==============================] - 1s 118us/step - loss: -6.3163 - acc: 0.5194\n",
      "Epoch 395/500\n",
      "11054/11054 [==============================] - 1s 118us/step - loss: -6.3034 - acc: 0.5132\n",
      "Epoch 396/500\n",
      "11054/11054 [==============================] - 1s 120us/step - loss: -6.3103 - acc: 0.5185\n",
      "Epoch 397/500\n",
      "11054/11054 [==============================] - 1s 122us/step - loss: -6.3393 - acc: 0.5221\n",
      "Epoch 398/500\n",
      "11054/11054 [==============================] - 1s 119us/step - loss: -6.3555 - acc: 0.5205\n",
      "Epoch 399/500\n",
      "11054/11054 [==============================] - 1s 120us/step - loss: -6.3855 - acc: 0.5227\n",
      "Epoch 400/500\n",
      "11054/11054 [==============================] - 1s 119us/step - loss: -6.3450 - acc: 0.5205\n",
      "Epoch 401/500\n",
      "11054/11054 [==============================] - 1s 118us/step - loss: -6.3821 - acc: 0.5226\n",
      "Epoch 402/500\n",
      "11054/11054 [==============================] - 1s 119us/step - loss: -6.3819 - acc: 0.5216\n",
      "Epoch 403/500\n",
      "11054/11054 [==============================] - 1s 119us/step - loss: -6.3819 - acc: 0.5246\n",
      "Epoch 404/500\n",
      "11054/11054 [==============================] - 1s 120us/step - loss: -6.3032 - acc: 0.5160\n",
      "Epoch 405/500\n",
      "11054/11054 [==============================] - 1s 120us/step - loss: -6.3415 - acc: 0.5175\n",
      "Epoch 406/500\n",
      "11054/11054 [==============================] - 1s 118us/step - loss: -6.3292 - acc: 0.5180\n",
      "Epoch 407/500\n",
      "11054/11054 [==============================] - 1s 122us/step - loss: -6.3566 - acc: 0.5211\n",
      "Epoch 408/500\n",
      "11054/11054 [==============================] - 1s 119us/step - loss: -6.3490 - acc: 0.5194\n",
      "Epoch 409/500\n",
      "11054/11054 [==============================] - 1s 119us/step - loss: -6.3766 - acc: 0.5210\n",
      "Epoch 410/500\n",
      "11054/11054 [==============================] - 1s 120us/step - loss: -6.3735 - acc: 0.5238\n",
      "Epoch 411/500\n",
      "11054/11054 [==============================] - 1s 127us/step - loss: -6.3645 - acc: 0.5221\n",
      "Epoch 412/500\n",
      "11054/11054 [==============================] - 2s 141us/step - loss: -6.3389 - acc: 0.5189\n",
      "Epoch 413/500\n",
      "11054/11054 [==============================] - 1s 135us/step - loss: -6.3806 - acc: 0.5217\n",
      "Epoch 414/500\n",
      "11054/11054 [==============================] - 2s 138us/step - loss: -6.3888 - acc: 0.5236\n",
      "Epoch 415/500\n",
      "11054/11054 [==============================] - 2s 137us/step - loss: -6.3527 - acc: 0.5171\n",
      "Epoch 416/500\n",
      "11054/11054 [==============================] - 2s 139us/step - loss: -6.3298 - acc: 0.5174\n",
      "Epoch 417/500\n",
      "11054/11054 [==============================] - 2s 144us/step - loss: -6.3382 - acc: 0.5147\n",
      "Epoch 418/500\n",
      "11054/11054 [==============================] - 2s 138us/step - loss: -6.3423 - acc: 0.5219\n",
      "Epoch 419/500\n",
      "11054/11054 [==============================] - 1s 120us/step - loss: -6.3531 - acc: 0.5227\n",
      "Epoch 420/500\n",
      "11054/11054 [==============================] - 1s 121us/step - loss: -6.3962 - acc: 0.5260\n",
      "Epoch 421/500\n",
      "11054/11054 [==============================] - 1s 122us/step - loss: -6.3514 - acc: 0.5202\n",
      "Epoch 422/500\n",
      "11054/11054 [==============================] - 1s 121us/step - loss: -6.3239 - acc: 0.5194\n",
      "Epoch 423/500\n",
      "11054/11054 [==============================] - 1s 121us/step - loss: -6.3749 - acc: 0.5198\n",
      "Epoch 424/500\n",
      "11054/11054 [==============================] - 1s 122us/step - loss: -6.3989 - acc: 0.5229\n",
      "Epoch 425/500\n",
      "11054/11054 [==============================] - 1s 122us/step - loss: -6.3677 - acc: 0.5213\n",
      "Epoch 426/500\n",
      "11054/11054 [==============================] - 1s 123us/step - loss: -6.3329 - acc: 0.5179\n",
      "Epoch 427/500\n",
      "11054/11054 [==============================] - 1s 122us/step - loss: -6.3664 - acc: 0.5163\n",
      "Epoch 428/500\n",
      "11054/11054 [==============================] - 1s 122us/step - loss: -6.3646 - acc: 0.5204\n",
      "Epoch 429/500\n",
      "11054/11054 [==============================] - 1s 122us/step - loss: -6.3669 - acc: 0.5184\n",
      "Epoch 430/500\n",
      "11054/11054 [==============================] - 1s 123us/step - loss: -6.3592 - acc: 0.5204\n",
      "Epoch 431/500\n",
      "11054/11054 [==============================] - 1s 122us/step - loss: -6.3652 - acc: 0.5237\n",
      "Epoch 432/500\n",
      "11054/11054 [==============================] - 1s 122us/step - loss: -6.3771 - acc: 0.5248\n",
      "Epoch 433/500\n",
      "11054/11054 [==============================] - 1s 122us/step - loss: -6.3724 - acc: 0.5205\n",
      "Epoch 434/500\n",
      "11054/11054 [==============================] - 1s 123us/step - loss: -6.3710 - acc: 0.5212\n",
      "Epoch 435/500\n",
      "11054/11054 [==============================] - 1s 122us/step - loss: -6.3353 - acc: 0.5213\n",
      "Epoch 436/500\n",
      "11054/11054 [==============================] - 1s 124us/step - loss: -6.3611 - acc: 0.5213\n",
      "Epoch 437/500\n",
      "11054/11054 [==============================] - 1s 122us/step - loss: -6.3327 - acc: 0.5207\n",
      "Epoch 438/500\n",
      "11054/11054 [==============================] - 1s 123us/step - loss: -6.3281 - acc: 0.5165\n",
      "Epoch 439/500\n",
      "11054/11054 [==============================] - 1s 123us/step - loss: -6.3928 - acc: 0.5233\n",
      "Epoch 440/500\n",
      "11054/11054 [==============================] - 1s 123us/step - loss: -6.3371 - acc: 0.5160\n",
      "Epoch 441/500\n",
      "11054/11054 [==============================] - 1s 122us/step - loss: -6.4050 - acc: 0.5246\n",
      "Epoch 442/500\n",
      "11054/11054 [==============================] - 1s 124us/step - loss: -6.3739 - acc: 0.5211\n",
      "Epoch 443/500\n",
      "11054/11054 [==============================] - 1s 122us/step - loss: -6.3926 - acc: 0.5243\n",
      "Epoch 444/500\n",
      "11054/11054 [==============================] - 1s 123us/step - loss: -6.3440 - acc: 0.5191\n",
      "Epoch 445/500\n",
      "11054/11054 [==============================] - 1s 124us/step - loss: -6.3352 - acc: 0.5195\n",
      "Epoch 446/500\n",
      "11054/11054 [==============================] - 1s 127us/step - loss: -6.3655 - acc: 0.5212\n",
      "Epoch 447/500\n",
      "11054/11054 [==============================] - 1s 123us/step - loss: -6.3517 - acc: 0.5204\n",
      "Epoch 448/500\n",
      "11054/11054 [==============================] - 1s 124us/step - loss: -6.3608 - acc: 0.5232\n",
      "Epoch 449/500\n",
      "11054/11054 [==============================] - 1s 127us/step - loss: -6.3457 - acc: 0.5211\n",
      "Epoch 450/500\n",
      "11054/11054 [==============================] - 2s 142us/step - loss: -6.3215 - acc: 0.5151\n",
      "Epoch 451/500\n",
      "11054/11054 [==============================] - 2s 136us/step - loss: -6.3824 - acc: 0.5244\n",
      "Epoch 452/500\n",
      "11054/11054 [==============================] - 1s 133us/step - loss: -6.2898 - acc: 0.5148\n",
      "Epoch 453/500\n",
      "11054/11054 [==============================] - 1s 135us/step - loss: -6.3642 - acc: 0.5213\n",
      "Epoch 454/500\n",
      "11054/11054 [==============================] - 2s 140us/step - loss: -6.3813 - acc: 0.5245\n",
      "Epoch 455/500\n",
      "11054/11054 [==============================] - 2s 165us/step - loss: -6.4057 - acc: 0.5243\n",
      "Epoch 456/500\n",
      "11054/11054 [==============================] - 2s 143us/step - loss: -6.3403 - acc: 0.5185\n",
      "Epoch 457/500\n",
      "11054/11054 [==============================] - 2s 139us/step - loss: -6.3943 - acc: 0.5248\n",
      "Epoch 458/500\n",
      "11054/11054 [==============================] - 2s 146us/step - loss: -6.3572 - acc: 0.5204\n",
      "Epoch 459/500\n",
      "11054/11054 [==============================] - 2s 142us/step - loss: -6.3862 - acc: 0.5222\n",
      "Epoch 460/500\n",
      "11054/11054 [==============================] - 2s 139us/step - loss: -6.2924 - acc: 0.5167\n",
      "Epoch 461/500\n",
      "11054/11054 [==============================] - 2s 143us/step - loss: -6.3399 - acc: 0.5210\n",
      "Epoch 462/500\n",
      "11054/11054 [==============================] - 2s 142us/step - loss: -6.3367 - acc: 0.5161\n",
      "Epoch 463/500\n",
      "11054/11054 [==============================] - 2s 148us/step - loss: -6.3015 - acc: 0.5184\n",
      "Epoch 464/500\n",
      "11054/11054 [==============================] - 2s 143us/step - loss: -6.3243 - acc: 0.5147\n",
      "Epoch 465/500\n",
      "11054/11054 [==============================] - 1s 134us/step - loss: -6.3371 - acc: 0.5196\n",
      "Epoch 466/500\n",
      "11054/11054 [==============================] - 1s 132us/step - loss: -6.3307 - acc: 0.5148\n",
      "Epoch 467/500\n",
      "11054/11054 [==============================] - 1s 132us/step - loss: -6.3786 - acc: 0.5216\n",
      "Epoch 468/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11054/11054 [==============================] - 1s 119us/step - loss: -6.4033 - acc: 0.5256\n",
      "Epoch 469/500\n",
      "11054/11054 [==============================] - 1s 118us/step - loss: -6.3800 - acc: 0.5242\n",
      "Epoch 470/500\n",
      "11054/11054 [==============================] - 1s 124us/step - loss: -6.3664 - acc: 0.5173\n",
      "Epoch 471/500\n",
      "11054/11054 [==============================] - 1s 127us/step - loss: -6.3696 - acc: 0.5217\n",
      "Epoch 472/500\n",
      "11054/11054 [==============================] - 1s 120us/step - loss: -6.3614 - acc: 0.5147\n",
      "Epoch 473/500\n",
      "11054/11054 [==============================] - 1s 135us/step - loss: -6.3805 - acc: 0.5213\n",
      "Epoch 474/500\n",
      "11054/11054 [==============================] - 1s 121us/step - loss: -6.3981 - acc: 0.5219\n",
      "Epoch 475/500\n",
      "11054/11054 [==============================] - 1s 119us/step - loss: -6.3715 - acc: 0.5157\n",
      "Epoch 476/500\n",
      "11054/11054 [==============================] - 1s 118us/step - loss: -6.3263 - acc: 0.5181\n",
      "Epoch 477/500\n",
      "11054/11054 [==============================] - 1s 123us/step - loss: -6.3246 - acc: 0.5086\n",
      "Epoch 478/500\n",
      "11054/11054 [==============================] - 1s 119us/step - loss: -6.3256 - acc: 0.5136\n",
      "Epoch 479/500\n",
      "11054/11054 [==============================] - 1s 118us/step - loss: -6.3560 - acc: 0.5203\n",
      "Epoch 480/500\n",
      "11054/11054 [==============================] - 1s 119us/step - loss: -6.3274 - acc: 0.5144\n",
      "Epoch 481/500\n",
      "11054/11054 [==============================] - 1s 121us/step - loss: -6.3995 - acc: 0.5223\n",
      "Epoch 482/500\n",
      "11054/11054 [==============================] - 1s 123us/step - loss: -6.3512 - acc: 0.5163\n",
      "Epoch 483/500\n",
      "11054/11054 [==============================] - 1s 119us/step - loss: -6.3670 - acc: 0.5172\n",
      "Epoch 484/500\n",
      "11054/11054 [==============================] - 1s 120us/step - loss: -6.3920 - acc: 0.5186\n",
      "Epoch 485/500\n",
      "11054/11054 [==============================] - 1s 119us/step - loss: -6.3501 - acc: 0.5152\n",
      "Epoch 486/500\n",
      "11054/11054 [==============================] - 1s 119us/step - loss: -6.3483 - acc: 0.5156\n",
      "Epoch 487/500\n",
      "11054/11054 [==============================] - 1s 120us/step - loss: -6.3809 - acc: 0.5204\n",
      "Epoch 488/500\n",
      "11054/11054 [==============================] - 1s 120us/step - loss: -6.3772 - acc: 0.5234\n",
      "Epoch 489/500\n",
      "11054/11054 [==============================] - 1s 120us/step - loss: -6.3633 - acc: 0.5185\n",
      "Epoch 490/500\n",
      "11054/11054 [==============================] - 1s 121us/step - loss: -6.3732 - acc: 0.5104\n",
      "Epoch 491/500\n",
      "11054/11054 [==============================] - 1s 119us/step - loss: -6.4009 - acc: 0.5165\n",
      "Epoch 492/500\n",
      "11054/11054 [==============================] - 1s 124us/step - loss: -6.3407 - acc: 0.5182\n",
      "Epoch 493/500\n",
      "11054/11054 [==============================] - 1s 120us/step - loss: -6.4017 - acc: 0.5215\n",
      "Epoch 494/500\n",
      "11054/11054 [==============================] - 1s 120us/step - loss: -6.3258 - acc: 0.5152\n",
      "Epoch 495/500\n",
      "11054/11054 [==============================] - 1s 120us/step - loss: -6.3534 - acc: 0.5107\n",
      "Epoch 496/500\n",
      "11054/11054 [==============================] - 1s 120us/step - loss: -6.3590 - acc: 0.5130\n",
      "Epoch 497/500\n",
      "11054/11054 [==============================] - 1s 120us/step - loss: -6.3565 - acc: 0.5140\n",
      "Epoch 498/500\n",
      "11054/11054 [==============================] - 1s 121us/step - loss: -6.3647 - acc: 0.5157\n",
      "Epoch 499/500\n",
      "11054/11054 [==============================] - 1s 121us/step - loss: -6.2740 - acc: 0.5148\n",
      "Epoch 500/500\n",
      "11054/11054 [==============================] - 1s 121us/step - loss: -6.3354 - acc: 0.5147\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1809c5b6f28>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the data to the training dataset\n",
    "classifier.fit(features_train,labels_train, batch_size=10, epochs=500, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11054/11054 [==============================] - 0s 21us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-6.387123471728194, 0.5124841686321335]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model=classifier.evaluate(features_train, labels_train)\n",
    "eval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test=features[10000:]\n",
    "labels_test=labels[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=classifier.predict(features_test)\n",
    "y_pred =[1 if pred>0.5 else -1 for pred in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.93      0.97      0.95       460\n",
      "           1       0.98      0.95      0.96       594\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      1054\n",
      "   macro avg       0.96      0.96      0.96      1054\n",
      "weighted avg       0.96      0.96      0.96      1054\n",
      "\n",
      "The accuracy is: 95.73055028462998 %\n",
      "[[447  13]\n",
      " [ 32 562]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(labels_test, y_pred))\n",
    "print('The accuracy is:', 100*accuracy_score(labels_test, y_pred),'%')\n",
    "print(confusion_matrix(labels_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total Data Accuracy\n",
    "y_pred_total=classifier.predict(features)\n",
    "y_pred_total =[1 if pred>0.5 else -1 for pred in y_pred_total]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.91      0.98      0.94      4897\n",
      "           1       0.98      0.92      0.95      6157\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     11054\n",
      "   macro avg       0.95      0.95      0.95     11054\n",
      "weighted avg       0.95      0.95      0.95     11054\n",
      "\n",
      "The accuracy is: 94.68065858512756 %\n",
      "[[4801   96]\n",
      " [ 492 5665]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(labels, y_pred_total))\n",
    "print('The accuracy is:', 100*accuracy_score(labels, y_pred_total),'%')\n",
    "print(confusion_matrix(labels, y_pred_total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
